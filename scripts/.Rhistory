m_av01 <- lmer(RTs ~ trial + (1 | participant), data = av)
# get coefficients for individual participants:
m_av01_coef <- coef(m_av01)$participant %>% rownames_to_column() %>%
setNames(c("participant", "intercept", "slope"))
# visualize varying intercepts:
left_join(av, m_av01_coef) %>%
ggplot(aes(x = trial, y = RTs)) +
geom_point() + facet_wrap(~ participant) +
geom_abline(aes(intercept = intercept, slope = slope),
col = "blue", lty = 2)
# add varying slopes:
m_av02 <- lmer(RTs ~ trial + (1 + trial | participant), data = av)
# get coefficients:
m_av02_coef <- coef(m_av02)$participant %>% rownames_to_column() %>%
setNames(c("participant", "intercept02", "slope02"))
left_join(left_join(av, m_av01_coef), m_av02_coef) %>%
ggplot(aes(x = trial, y = RTs)) +
geom_point() + facet_wrap(~ participant) +
geom_abline(aes(intercept = intercept, slope = slope),
col = "blue", lty = 2) +
geom_abline(aes(intercept = intercept02, slope = slope02),
col = "red", lty = 3) +
geom_abline(aes(intercept = coef(m_av)[1],
slope = coef(m_av)[2]),
lty = 4, col = "grey")
# load data (from languageR)
data("lexdec")
# remove outliers, only use correct answers
lexdec2 <- lexdec[lexdec$RT < 7, ]
lexdec3 <- lexdec2[lexdec2$Correct == "correct", ]
# center relevant data
lexdec3$Frequency.c <- scale(lexdec3$Frequency, scale = F)
lexdec3$Trial.c <- scale(lexdec3$Trial, scale = F)
# plot each participant in a single panel
xylowess.fnc(RT ~ Trial | Subject, data = lexdec3,
ylabel = "log RT", xlabel = "Trial")
# model: Reaction Time ~ Frequency
m1 <- lme4::lmer(RT ~ Frequency.c +
(1 | Subject) +
(1 | Word),
data = lexdec3,
REML = F) # REML: restricted maximum likelihood
factorial(20)
set.seed(1)
n <- 100
tr <- rbinom(100, 1, 0.5)
y <- 1 + tr + rnorm(n, 0, 3)
tr
y
diff(by(y, tr, mean))
y <- c(6,5,5,3,4,5,6,7)
diff(by(y, tr, mean))
y <- 1 + tr + rnorm(n, 0, 3)
y
str(y)
y <- c(6,5,5,3,4,5,6,7)
str(y)
tr
y <- sample(1:6, 100)
y <- sample(1:6, 100, replace = T)
diff(by(y, tr, mean))
# install a package
!require("tidyerse")
# install a package
!require("tidyverse")
69+28.95
47.5+20.75
library(collostructions)
?collex.distst
?collex.dist
set.seed(123)
library(zipfR)
set.seed(123)
d <- data.frame(cxn = sample(c("A", "B"), 100, replace = T),
freq1 = rnorm(100, mean = 50, sd = 20),
freq2 = rnorm(100, mean = 50, sd = 20))
d
set.seed(123)
d <- data.frame(cxn = sample(c("A", "B"), 100, replace = T),
freq1 = round(rnorm(100, mean = 50, sd = 20)),
freq2 = round(rnorm(100, mean = 50, sd = 20)))
d
collex.dist(d)
subset(collex.dist(d), SIGNIF != "ns")
d2 <- d
d2$freq1 <- d2$freq1*10
d2$freq2 <- d2$freq2*10
subset(collex.dist(d), SIGNIF != "ns")
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d2), SIGNIF != "ns"))
head(subset(collex.dist(d), SIGNIF != "ns"))
head(subset(collex.dist(d2), SIGNIF != "ns"))
fion <- readxl::read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx")
View(fion)
silvie <- readxl::read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx")
View(silvie)
sum(fion$n)
sum(fion$n_CHI)
sum(fion$n_CDS)
sum(silvie$n_CHI)
sum(silvie$n_CDS)
sum(fion$n_CHI)+sum(fion$n_CDS)+sum(silvie$n_CHI)+sum(silvie$n_CDS)
library(tidyverse)
library(readxl)
?readxl::excel_sheets
excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx")
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx"))
fion$n_CHI+fion$n_CDS
sum(fion$n_CHI)+sum(fion$n_CDS)
for(i in 1:21) {
fion <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(fion$n_CHI)+sum(fion$n_CDS)
} else {
n_all <- n_all + sum(fion$n_CHI)+sum(fion$n_CDS)
}
}
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist.xlsx"))
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx"))
for(i in 1:10) {
silvie <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
library(tidyverse)
library(readxl)
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx"))
length(excel_sheets("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx"))
for(i in 1:21) {
fion <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/fion_wordlist.xlsx", sheet = i)
if(i == 1) {
n_all <- sum(fion$n_CHI)+sum(fion$n_CDS)
} else {
n_all <- n_all + sum(fion$n_CHI)+sum(fion$n_CDS)
}
}
for(i in 1:10) {
silvie <- read_xlsx("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist02.xlsx", sheet = i)
if(i == 1) {
n_all_silvie <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all_silvie <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
n_all+n_all_silvie
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist", full.names = T)
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/silvie_wordlist", full.names = T)
for(i in 1:length(f)) {
silvie <- read_xlsx(f[i])
if(i == 1) {
n_all_silvie <- sum(silvie$n_CHI)+sum(silvie$n_CDS)
} else {
n_all_silvie <- n_all + sum(silvie$n_CHI)+sum(silvie$n_CDS)
}
}
n_all+n_all_silvie
f <- list.files("/Users/stefanhartmann/sciebo/Sciebo Documents/Bilingual_Language_Acquisition/Raw_data_May2020/lily_wordlist", full.names = T)
for(i in 1:length(f)) {
lily <- read_xlsx(f[i])
if(i == 1) {
n_all_lily <- sum(lily$n_CHI)+sum(lily$n_CDS)
} else {
n_all_lily <- n_all + sum(lily$n_CHI)+sum(lily$n_CDS)
}
}
n_all+n_all_silvie+n_all_lily
install.packages("quanteda")
library(gutenbergr)
gutenberg_languages
filter(gutenberg_languages, language=="de")
library(tidyverse)
gl <- gutenberg_languages
filter(gl, language=="de")
glde <- filter(gl, language=="de")
gutenberg_metadata
gutenberg_metadata
586.2*6
586.2*9
586.2*6
586.2*8
707.62*6
4689.6+4245.72
544.33*4
544.33*5
544.33*6
544.33*4
544.33*5
3000/707.62
707.62*4
707.62*4.5
10+6+2+8+18
# relative Bestehensgrenze:
117.5*0.78
# Punktverteilung
seq(91, 160, length.out = 11)
127+139+148+145+119+112
790/6
0.78*131.66
60+88+69
217/3
library(tidyverse)
d <- read_csv("/Users/stefanhartmann/sciebo/ARENAS WP2/Data DE 12022024/germany.csv")
d$Text
grep("#genderwahn", d)
grep("#genderwahn", d$Text)
grep("genderwahn", d$Text, ignore.case = T)
grep("gender", d$Text, ignore.case = T)
library(writexl)
d[grep("gender", d$Text, ignore.case = T),]
d[grep("gender", d$Text, ignore.case = T),] %>% write_xlsx("gender_twitter.xlsx")
d <- read_csv("/Users/stefanhartmann/sciebo/ARENAS WP2/Data DE 12022024/facebook-de.csv")
d[grep("gender", d$`Post, Text`, ignore.case = T),] %>% write_xlsx("gender_twitter.xlsx")
d <- read_csv("/Users/stefanhartmann/sciebo/ARENAS WP2/Data DE 12022024/germany.csv")
d[grep("gender", d$Text, ignore.case = T),] %>% write_xlsx("gender_twitter.xlsx")
d <- read_csv("/Users/stefanhartmann/sciebo/ARENAS WP2/Data DE 12022024/facebook-de.csv")
d[grep("gender", d$Text, ignore.case = T),] %>% write_xlsx("gender_fb.xlsx")
d[grep("gender", d$`Post, Text`, ignore.case = T),] %>% write_xlsx("gender_fb.xlsx")
d[grep("gender", d$`Post, Text`, ignore.case = T),]
d <- read_csv("/Users/stefanhartmann/sciebo/ARENAS WP2/Data DE 12022024/youtube-GER-clean.csv")
d[grep("gender", d$`Post, Text`, ignore.case = T),] %>% write_xlsx("gender_youtube.xlsx")
d[grep("gender", d$`Comment, Text`, ignore.case = T),] %>% write_xlsx("gender_youtube.xlsx")
d[grep("gender", d$`Comment, Text`, ignore.case = T),]
library(tidyverse)
1500*12
1200*12
1000*12
900*12
160000*0.63
100800+(0.63*100800)
setwd("~/sciebo/Projekte/Dataviz-Evalmo/scripts")
# read data
d <- read_csv("../data/chen_lein.csv.zip", quote = "\"")
# install.packages("tidyverse")
library(tidyverse)
library(readxl)
# Vectors
my_vector <- c(1,2,3)
my_character_vector <- c("a", "b", "c")
my_other_character_vector <- c(1, "two", 3)
# Data frames
my_data_frame <- data.frame(names = c("Jack", "Jill", "Hensel", "Gretel"),
gingerbread = c(5, 6, 2, 10) )
my_data_frame[2,2]
my_data_frame[3,1]
rownames(my_data_frame)
my_second_data_frame <- data.frame(A = my_vector, B = my_character_vector,
C = my_other_character_vector)
# Matrices
my_matrix <- matrix(c(1,2,3,4,5,6), ncol = 2)
# Lists
my_list <- list(my_vector, my_data_frame, my_matrix)
my_vector[2]
my_list[[2]][3,2]
# logical
my_logical_object <- my_list[[2]][3,2] == 2
test <- 2
test2 = 2
test == test2
# character
my_character_object <- "hi"
# numeric
my_numeric_object <- sqrt(5)
# integer
my_integer_object <- 5
my_integer_object <- as.integer(my_integer_object)
is.integer(my_integer_object)
# factors
my_data_frame2 <- my_data_frame
my_data_frame$names <- factor(my_data_frame$names)
str(my_data_frame)
my_data_frame2[5,] <- c("James", 4)
my_data_frame2
my_data_frame[5,] <- c("James", 4)
my_data_frame <- my_data_frame[-5,]
my_data_frame$names
my_data_frame$names <- factor(my_data_frame$names, levels = c("Hensel", "Gretel", "Jack", "Jill"))
my_data_frame$names
# Loops
squareroots <- NA
for(i in 1:100) {
squareroots[i] <- sqrt(i)
}
# Functions
get_squareroot <- function(range) {
squareroots <- NA
for(i in range) {
squareroots[i] <- sqrt(i)
}
return(squareroots)
}
# apply
sapply(1:100, function(i) sqrt(i))
######################################
## concrete application:  chen/lein ##
######################################
# read data
d <- read_csv("../data/chen_lein.csv.zip", quote = "\"")
# structure of the data frame
str(d)
colnames(d)
d$Key
d$tag0002
colnames(d)
?rename
rename_with(d, "Lemma", "tag0002")
rename_with(d, ~"Lemma", "tag0002")
d <- rename_with(d, ~"Lemma", "tag0002")
# add a column indicating whether the lemma
# ends with chen or lein
ifelse(grepl(".*lein$", d$Lemma), "lein", "chen")
# add a column indicating whether the lemma
# ends with chen or lein
d$Variant <- ifelse(grepl(".*lein$", d$Lemma), "lein", "chen")
d$file_decade
# plot relative frequency of variant over time
ggplot(d, aes(x = file_decade, y = variant)) +
geom_bar()
# plot relative frequency of variant over time
ggplot(d, aes(x = file_decade, y = Variant)) +
geom_bar()
# plot relative frequency of variant over time
ggplot(d, aes(x = file_decade, y = Variant)) +
geom_col()
# plot relative frequency of variant over time
ggplot(d, aes(x = factor(file_decade), y = Variant)) +
geom_col()
# plot relative frequency of variant over time
ggplot(d, aes(x = factor(file_decade), y = Variant)) +
geom_col(position = "stack")
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
)
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, group = Variant)) +
geom_bar()
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, group = Variant)) +
geom_col()
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col()
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = position_dodge())
# or stacked barplot with bars summing up to 100%
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill")
# we can also group by text type
d$file_genre
# we can also group by text type
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill") + facet_wrap(~text_type)
# we can also group by text type
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill") + facet_wrap(~file_genre)
# we can also group by text type
d %>% group_by(file_decade, file_genre, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill") + facet_wrap(~file_genre)
# we can also group by text type
d %>% group_by(file_decade, file_genre, Variant) %>% summarise(
n = n()
) %>% na.omit %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill") + facet_wrap(~file_genre)
# we can also group by text type
d %>% group_by(file_decade, file_genre, Variant) %>% summarise(
n = n()
) %>% na.omit %>%
ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill") + facet_wrap(~file_genre)
# we can also group by text type
d %>% group_by(file_decade, file_genre, Variant) %>% summarise(
n = n()
) %>% na.omit %>%
ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "dodge") + facet_wrap(~file_genre)
library(languageR)
load(RTs)
?languageR
lexdec
lexdec$RT
# install.packages("tidyverse")
library(tidyverse)
library(readxl)
# Vectors
my_vector <- c(1,2,3)
my_character_vector <- c("a", "b", "c")
my_other_character_vector <- c(1, "two", 3)
# Data frames
my_data_frame <- data.frame(names = c("Jack", "Jill", "Hensel", "Gretel"),
gingerbread = c(5, 6, 2, 10) )
my_data_frame[2,2]
my_data_frame[3,1]
rownames(my_data_frame)
my_second_data_frame <- data.frame(A = my_vector, B = my_character_vector,
C = my_other_character_vector)
# Matrices
my_matrix <- matrix(c(1,2,3,4,5,6), ncol = 2)
# Lists
my_list <- list(my_vector, my_data_frame, my_matrix)
my_vector[2]
my_list[[2]][3,2]
# logical
my_logical_object <- my_list[[2]][3,2] == 2
test <- 2
test2 = 2
test == test2
# character
my_character_object <- "hi"
# numeric
my_numeric_object <- sqrt(5)
# integer
my_integer_object <- 5
my_integer_object <- as.integer(my_integer_object)
is.integer(my_integer_object)
# factors
my_data_frame2 <- my_data_frame
my_data_frame$names <- factor(my_data_frame$names)
str(my_data_frame)
my_data_frame2[5,] <- c("James", 4)
my_data_frame2
my_data_frame[5,] <- c("James", 4)
my_data_frame <- my_data_frame[-5,]
my_data_frame$names
my_data_frame$names <- factor(my_data_frame$names, levels = c("Hensel", "Gretel", "Jack", "Jill"))
my_data_frame$names
# Loops
squareroots <- NA
for(i in 1:100) {
squareroots[i] <- sqrt(i)
}
# Functions
get_squareroot <- function(range) {
squareroots <- NA
for(i in range) {
squareroots[i] <- sqrt(i)
}
return(squareroots)
}
# apply
sapply(1:100, function(i) sqrt(i))
# read data
d <- read_csv("../data/chen_lein.csv.zip", quote = "\"")
# structure of the data frame
str(d)
colnames(d) # tag0002 is the lemma column
# rename the column (using dplyr's rename_with)
d <- rename_with(d, ~"Lemma", "tag0002")
# add a column indicating whether the lemma
# ends with chen or lein
d$Variant <- ifelse(grepl(".*lein$", d$Lemma), "lein", "chen")
# plot relative frequency of variant over time
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = position_dodge())
# or stacked barplot with bars summing up to 100%
d %>% group_by(file_decade, Variant) %>% summarise(
n = n()
) %>% ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "fill")
# we can also group by text type
d %>% group_by(file_decade, file_genre, Variant) %>% summarise(
n = n()
) %>% na.omit %>%
ggplot(aes(x = factor(file_decade), y = n, fill = Variant)) +
geom_col(position = "dodge") + facet_wrap(~file_genre)
# read dataset
rts <- read_xlsx("../data/fake_RT_data.xlsx")
# inspect data
rts
# use pivot_longer()
?pivot_longer
colnames(rts)
# as input for pivot_longer
pivot_longer(rts, cols = starts_with("ReactionTime_"))
# as input for pivot_longer
pivot_longer(rts, cols = starts_with("ReactionTime_"),
names_prefix="ReactionTime_")
# as input for pivot_longer
pivot_longer(rts, cols = starts_with("ReactionTime_"),
names_prefix="ReactionTime_Condition")
# as input for pivot_longer
pivot_longer(rts, cols = starts_with("ReactionTime_"),
names_prefix="ReactionTime_Condition",
names_to="Condition", values_to = "RT")
# as input for pivot_longer
rts2 <- pivot_longer(rts, cols = starts_with("ReactionTime_"),
names_prefix="ReactionTime_Condition",
names_to="Condition", values_to = "RT")
# this can be used as input for a ggplot!
ggplot(rts2, aes(x = Condition, y = RT)) + geom_boxplot()
